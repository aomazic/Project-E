{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(row):\n",
    "    csv_data = []  # Create an empty list for each data point\n",
    "\n",
    "    # Add comments for each section\n",
    "    csv_data.append(\"<s>[INST] The following information represents a non-playable character in a game. Use this information to simulate a response from the character.\\n\")\n",
    "    csv_data.append(\"###character: \")\n",
    "    csv_data.append(row[\"character\"])\n",
    "    csv_data.append(\"###question: \")\n",
    "    csv_data.append(row[\"question\"])\n",
    "    csv_data.append(\"###memory: \")\n",
    "    csv_data.append(row[\"memory\"])\n",
    "    csv_data.append(\"[/INST]\\n\")\n",
    "\n",
    "    # Add response and action\n",
    "    csv_data.append(\"###response: \")\n",
    "    csv_data.append(row[\"response\"])\n",
    "    csv_data.append(\"###action: \")\n",
    "    csv_data.append(row[\"action\"])\n",
    "    csv_data.append(\"</s>\")\n",
    "\n",
    "    formatted_data = \" \".join(csv_data)\n",
    "\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_columns(dataset):\n",
    "    dataset[\"prediction\"] = convert_data(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load your JSON data\n",
    "with open(\"dataset.json\", \"r\") as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "df = pd.DataFrame(json_data)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('formatted_dataset.csv', index=False)\n",
    "\n",
    "# Load the CSV file as a Dataset\n",
    "data = Dataset.from_csv('formatted_dataset.csv')\n",
    "\n",
    "data = data.map(merge_columns)\n",
    "\n",
    "print(data)\n",
    "print(data[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "data = dataset.map(lambda samples: tokenizer(samples['text']), batched=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
