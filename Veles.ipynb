{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aomazic/Project-E/blob/main/Veles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mixtral game master"
      ],
      "metadata": {
        "id": "L6FUl4b91H35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies setup"
      ],
      "metadata": {
        "id": "L8ciBOpe1P9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q bitsandbytes datasets accelerate loralib\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8sCxvBErmHC",
        "outputId": "9de5bf2f-eac0-4f76-abed-447aa7256df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data processing"
      ],
      "metadata": {
        "id": "AvZW06kA1f_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_data(row):\n",
        "    csv_data = []  # Create an empty list for each data point\n",
        "\n",
        "    # Add comments for each section\n",
        "    csv_data.append(\"<s>[INST] The following information represents a non-playable character in a game. Use this information to simulate a response from the character. The character can perform the following actions: goTo, eat, drink, speak, transfer. Each action has specific details associated with it, which are provided in the 'actionDetail' field.\\n Response formats are consistant : response:(Character response) action : {'type': (type), 'actionDetail': {'source': (source)), 'target': (target)}}\")\n",
        "    csv_data.append(\"###character: \")\n",
        "    csv_data.append(row[\"character\"])\n",
        "    csv_data.append(\"###question: \")\n",
        "    csv_data.append(row[\"question\"])\n",
        "    csv_data.append(\"###memory: \")\n",
        "    csv_data.append(row[\"memory\"])\n",
        "    csv_data.append(\"[/INST]\\n\")\n",
        "\n",
        "    # Add response and action\n",
        "    csv_data.append(\"###response: \")\n",
        "    csv_data.append(row[\"response\"])\n",
        "    csv_data.append(\"###action: \")\n",
        "    csv_data.append(row[\"action\"])\n",
        "    csv_data.append(\"</s>\")\n",
        "\n",
        "    formatted_data = \" \".join(csv_data)\n",
        "\n",
        "    return formatted_data"
      ],
      "metadata": {
        "id": "d3ZzUylWw1wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KHxFBBKTfE_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_columns(dataset):\n",
        "    dataset[\"prediction\"] = convert_data(dataset)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "un46SID4i3RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load your JSON data\n",
        "with open(\"dataset.json\", \"r\") as file:\n",
        "    json_data = json.load(file)\n",
        "\n",
        "df = pd.DataFrame(json_data)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "df.to_csv('formatted_dataset.csv', index=False)\n",
        "\n",
        "# Load the CSV file as a Dataset\n",
        "data = Dataset.from_csv('formatted_dataset.csv')\n",
        "\n",
        "data = data.map(merge_columns)\n",
        "\n",
        "print(data)\n",
        "print(data['prediction'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "01a794b0aecf49d1b855e8130b31fe85",
            "35edc87da9444d25951f45230057d75d",
            "7ed567aa51874eee80f33bba2f4341f9",
            "4e67cb9cfd5442e28451524444c5775d",
            "830e8e36ac6c4b3cac69dd36046704af",
            "a2dcfe011ce2448289ec0fad1ef05ddf",
            "049b5d49b08b4a8cb13fafc0945709b4",
            "7de566a21fda4f93ba9786714b2b6fd5",
            "9f5794fb85fc401597423eba62b4130b",
            "b7e3fdbc9513413e9af2b254834e5b14",
            "281dd5b0ce8e424bac9ceb1ddd955fc8",
            "9012b656a5194a859b610c236e8c394c",
            "191b7047f92d43a99f392708ef69f779",
            "ee9975e80bb347d29a5b3f50545b3a75",
            "cf402e40c4134cc0b10258c8ebbca45c",
            "3f852f43aa734f6fafe8f881228d2a87",
            "cb68519f18a4438388e633f500ab86d0",
            "2b9a272fbbb44c08a4e61f311ebe3659",
            "16fad0b60a6847c68dbc63215865ce29",
            "662a7e35ac664d73ad437a48409feea7",
            "caa431ac83194f22a63e170a982c7814",
            "ae37c86d0f9142faa3b1c825475029b0"
          ]
        },
        "id": "hYEoCMolxMis",
        "outputId": "db67f351-b553-49d4-f48e-36246d761ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01a794b0aecf49d1b855e8130b31fe85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9012b656a5194a859b610c236e8c394c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['character', 'question', 'memory', 'response', 'action', 'prediction'],\n",
            "    num_rows: 20\n",
            "})\n",
            "<s>[INST] The following information represents a non-playable character in a game. Use this information to simulate a response from the character. The character can perform the following actions: goTo, eat, drink, speak, transfer. Each action has specific details associated with it, which are provided in the 'actionDetail' field.\n",
            " Response formats are consistant : response:(Character response) action : {'type': (type), 'actionDetail': {'source': (source)), 'target': (target)}} ###character:  {'name': 'Fiona', 'age': 29, 'interests': ['Farming', 'Botany', 'Cooking'], 'description': 'Fiona is a skilled farmer who tends to her crops with care and expertise.'} ###question:  what to do today ###memory:  [{'date_created': '2023-02-02 08:00:00', 'recency': 8, 'importance': 7, 'activity': 'Spotted Ivan at 2023-02-01 10:00:00 in the World'}, {'date_created': '2023-02-01 10:00:00', 'recency': 8, 'importance': 7, 'activity': 'Thirst level at 80% at time 2023-02-01 10:00:00'}, {'date_created': '2023-01-31 12:00:00', 'recency': 8, 'importance': 7, 'activity': 'Told Ivan: How is your day?'}, {'date_created': '2023-01-30 12:00:00', 'recency': 8, 'importance': 7, 'activity': 'Spotted bench at location guard tower'}] [/INST]\n",
            " ###response:  I should go to the market ###action:  {'type': 'goTo', 'actionDetail': {'source': 'tavern', 'target': None}} </s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model setup"
      ],
      "metadata": {
        "id": "XvJ3qwK51qss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dA5jvf6aCAx",
        "outputId": "ac263538-5e26-4925-bed9-3d02f531eaac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA L4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mknXhE4ZiRe"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import bitsandbytes as bnb\n",
        "from transformers import (AutoTokenizer,\n",
        "                          AutoConfig,\n",
        "                          AutoModelForCausalLM,\n",
        "                          BitsAndBytesConfig)\n",
        "import torch\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config = bnb_config, device_map='auto')\n",
        "\n",
        "model.config.quantization_config.to_dict()"
      ],
      "metadata": {
        "id": "hV4pGh6A3mEk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "1374fdce622043a5acbb20fef97178b6",
            "67df3a3703c14c9ca4b9e41a4b9a0313",
            "50e176b9632448e79c1da388a9ae073a",
            "be39d8c4dcc04b2db46dcda7c24f342d",
            "e5332fa247fc4eafb8d5da6638e74c65",
            "0f87b2f86cfa446a8849e85c4a52310d",
            "17678cd3ffe84a18b2fcdface41452ff",
            "9aaa45b5f6484296bd4b3930902a17d8",
            "ee0d0650c73143e488cd248c9cff5e97",
            "d24dc10e9640464b86f21166cc0283e9",
            "22002d020a0f47f7aa7877b1bbcfe256"
          ]
        },
        "outputId": "7860672d-923f-433f-d413-ead2654693d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1374fdce622043a5acbb20fef97178b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'quant_method': <QuantizationMethod.BITS_AND_BYTES: 'bitsandbytes'>,\n",
              " '_load_in_8bit': False,\n",
              " '_load_in_4bit': True,\n",
              " 'llm_int8_threshold': 6.0,\n",
              " 'llm_int8_skip_modules': None,\n",
              " 'llm_int8_enable_fp32_cpu_offload': False,\n",
              " 'llm_int8_has_fp16_weight': False,\n",
              " 'bnb_4bit_quant_type': 'nf4',\n",
              " 'bnb_4bit_use_double_quant': False,\n",
              " 'bnb_4bit_compute_dtype': 'float16',\n",
              " 'bnb_4bit_quant_storage': 'uint8',\n",
              " 'load_in_4bit': True,\n",
              " 'load_in_8bit': False}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model finetuning"
      ],
      "metadata": {
        "id": "5GhKt7dl15wc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Freezing the original weights\n"
      ],
      "metadata": {
        "id": "xY1LtfdQ2BVz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ms8TacCq-pR"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False  # freeze the model - train adapters later\n",
        "  if param.ndim == 1:\n",
        "    # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
        "    param.data = param.data.to(torch.float32)\n",
        "\n",
        "model.gradient_checkpointing_enable()  # reduce number of stored activations\n",
        "model.enable_input_require_grads()\n",
        "\n",
        "class CastOutputToFloat(nn.Sequential):\n",
        "  def forward(self, x): return super().forward(x).to(torch.float32)\n",
        "model.lm_head = CastOutputToFloat(model.lm_head)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the LoRa Adapters"
      ],
      "metadata": {
        "id": "Hs7hqOTE2Fqc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BORRLQZTNozn"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFdQBZwvuoEL",
        "outputId": "0226b8b8-9a5b-4226-dd30-09849b6baa50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 6815744 || all params: 3758886912 || trainable%: 0.18132346515244138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "mo_rzOqY2Ksf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from datasets import load_dataset\n",
        "\n",
        "data = data.map(lambda samples: tokenizer(samples['prediction']), batched=True)\n",
        "\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=data,\n",
        "    args=transformers.TrainingArguments(\n",
        "        per_device_train_batch_size=4,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=20,\n",
        "        max_steps=40,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        logging_steps=1,\n",
        "        output_dir='outputs'\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555,
          "referenced_widgets": [
            "1dbd7e691f5741da87d2cb4828049976",
            "f66442be8c6f4e84a73b972c1fcf67b7",
            "55ccf9fdf0724378a1c75716c40af252",
            "7964818d2fb64f5bb71f98a2927a1525",
            "805041d8d6734dd4812aa6054d824bb6",
            "863015bfcc2842598f1234cb03188d83",
            "ddd130b963484cc8b7b058e3ab5e0324",
            "bf14ebb71af8472c83fdd3136c9a6106",
            "601d1e65c62342d4a6ee68a6756f1adb",
            "aed90636dfca4c13b8aba1c6b01b8c37",
            "b65d22d7ef0c42cb84a22fc6d86a592d"
          ]
        },
        "id": "TxC3cTm_upqg",
        "outputId": "a2c6bb7c-ae13-4ad8-ca6b-18d1fcca6f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1dbd7e691f5741da87d2cb4828049976"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 6/40 00:53 < 07:37, 0.07 it/s, Epoch 4/40]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.124300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.141100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.081500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.061100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-df08342aadca>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# silence the warnings. Please re-enable for inference!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1910\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1912\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1913\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3282\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3284\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2119\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2121\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2122\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2123\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge adapters and share on the ü§ó Hub"
      ],
      "metadata": {
        "id": "VtyipjxG2PXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "-ynR1bDCA-_B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "dadc99c937c64bfeaa464d253540fd86",
            "8c6c7dfe3ffb49e48440a70e677c0057",
            "c8f74cb4140141daaf18a33d5fc89c81",
            "04e4c7ba92d2466b9297bc9a7308bd77",
            "797ef7da27d643a9a3c10ddf057c25e5",
            "12ff394f655645a2bd5acb3a86981275",
            "cf4518d6206b4b7b9ece267b5c01b4d1",
            "d91e2a8b63aa4da69f2aedff7d21ed32",
            "6869cc34401642d0909ad7e5cf1694cc",
            "09cbc84fa5ca4760b3d2e28bfb8627a0",
            "ba30680c02cd4f9db21883fca3545362",
            "3bce2df409874c31bc348c4fa82199d2",
            "2d2929f4929247e196e142290fb99d39",
            "d2bde1c1b44743b6888a1893979f88a8",
            "b6e48f5113d54de296dafd9a46243a2d",
            "d66386d038394b50bd70610db730982e",
            "8efb8df1649d46e98c5636dc4335fea4",
            "1cac2ce1711d418ead60fade9826002c",
            "071c2d0f9da9499cb715d9dd6b94d6bc",
            "05dc1265eed64c58bcd6c5abf3d84ef4",
            "b9d98b3e29a44ba6bbf0bc6ed56ce8d5",
            "9dbb71f7ecc042769bc68ea93003d683",
            "defcd6dd974d41de93e82856642b854c",
            "d110a398bec84383833271fd6f360e5c",
            "fd940318283c4bc096bb7cf84c64b5bd",
            "a4421ff6121041268e85925860c17b59",
            "c68a5ed76790439e9332d442d2d66770",
            "2ab31a4d78b44ed384521a51736b469e",
            "7a0696e6354a41f4af6afa6cff7d8dd3",
            "80d2bb2cc2ef4637bbff2288e7287964",
            "f531f3222e5848a68dd24b486af68066",
            "610569f3b0f3489bb3c726fe159ee406"
          ]
        },
        "outputId": "97d9dc80-0a57-4b1e-9823-a050ce1e566a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dadc99c937c64bfeaa464d253540fd86"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"aomazic/Mistral-7B-Instruct-v0.2-veles\", use_auth_token=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "9yT8o6xpBGjU",
        "outputId": "20100d5f-06bf-453a-acc5-f795ce6a4c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:836: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/aomazic/Mistral-7B-Instruct-v0.2-veles/commit/08997c2a55a41308b72831539af601ffd30ab1f7', commit_message='Upload model', commit_description='', oid='08997c2a55a41308b72831539af601ffd30ab1f7', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load adapters from the Hub"
      ],
      "metadata": {
        "id": "7NcDdib82SYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model_id = \"aomazic/Mistral-7B-Instruct-v0.2-veles\"\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "print(config)"
      ],
      "metadata": {
        "id": "RDbFtDccj_ji",
        "outputId": "77f13bd5-15ec-4c82-a941-9173b1ffc743",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=True, r=16, target_modules={'v_proj', 'q_proj'}, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model_id = \"aomazic/Mistral-7B-Instruct-v0.2-veles\"\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, return_dict=True, quantization_config = bnb_config, device_map='auto')\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "\n",
        "# Load the Lora model\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)\n",
        "model.save_pretrained(\"veles\")\n",
        "\n",
        "merged_model = model.merge_and_unload()\n",
        "merged_model.save_pretrained(\"veles\",safe_serialization=True, max_shard_size=\"2GB\")\n",
        "\n",
        "merged_model.push_to_hub(\"aomazic/Mistral-7B-Instruct-v0.2-veles\", use_auth_token=True)\n",
        "\n",
        "input_ids = torch.ones(1, 1, dtype=torch.long)\n",
        "attention_mask = torch.ones(1, 1, dtype=torch.long)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OorvFrOkBdfp",
        "outputId": "88282bf8-f0ac-4c0c-89db-20c9756a1802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/None/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    400\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1222\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, headers, proxies, etag_timeout, endpoint, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1822\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1722\u001b[0;31m                 \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hf_file_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1723\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEntryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhttp_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1644\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1646\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    373\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    351\u001b[0m             )\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-664cf19d-7627b4d7380120cc3516f0bb;021ed2a3-6a35-474d-ad5e-b0c5e6770798)\n\nRepository Not Found for url: https://huggingface.co/None/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-2ab5bf512364>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbnb_4bit_compute_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantization_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnb_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    485\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                     \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m         ) from e\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "TD9RBtGi2Vf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = tokenizer(\"###character:  {'name': 'Fiona', 'age': 29, 'interests': ['Farming', 'Botany', 'Cooking'], 'description': 'Fiona is a skilled farmer who tends to her crops with care and expertise.'} ###question:  what to do today ###memory:  [{'date_created': '2023-02-02 08:00:00', 'recency': 8, 'importance': 7, 'activity': 'Spotted Ivan at 2023-02-01 10:00:00 in the World'}, {'date_created': '2023-02-01 10:00:00', 'recency': 8, 'importance': 7, 'activity': 'Thirst level at 80% at time 2023-02-01 10:00:00'}, {'date_created': '2023-01-31 12:00:00', 'recency': 8, 'importance': 7, 'activity': 'Told Ivan: How is your day?'}, {'date_created': '2023-01-30 12:00:00', 'recency': 8, 'importance': 7, 'activity': 'Spotted bench at location guard tower'}] [/INST]\", return_tensors='pt')\n",
        "\n",
        "with torch.cuda.amp.autocast():\n",
        "  output_tokens = merged_model.generate(**batch, max_new_tokens=400)\n",
        "\n",
        "print('\\n\\n', tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa8od_3VBeUR",
        "outputId": "dbe07745-ef44-4960-953d-3727f3a5fc18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1644: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " [INST] The following information represents a non-playable character in a game. Use this information to simulate a response from the character. The character can perform the following actions: goTo, eat, drink, speak, transfer. Each action has specific details associated with it, which are provided in the 'actionDetail' field.###character:  {'name': 'Fiona', 'age': 29, 'interests': ['Farming', 'Botany', 'Cooking'], 'description': 'Fiona is a skilled farmer who tends to her crops with care and expertise.'} ###question:  what to do today ###memory:  [{'date_created': '2023-02-02 08:00:00', 'recency': 8, 'importance': 7, 'activity': 'Spotted Ivan at 2023-02-01 10:00:00 in the World'}, {'date_created': '2023-02-01 10:00:00', 'recency': 8, 'importance': 7, 'activity': 'Thirst level at 80% at time 2023-02-01 10:00:00'}, {'date_created': '2023-01-31 12:00:00', 'recency': 8, 'importance': 7, 'activity': 'Told Ivan: How is your day?'}, {'date_created': '2023-01-30 12:00:00', 'recency': 8, 'importance': 7, 'activity': 'Spotted bench at location guard tower'}] [/INST] Based on the character's description and current memory, Fiona might respond as follows:\n",
            "\n",
            "Fiona: \"Hmm, let's see. I should check on my crops first thing. I've noticed some signs of pests lately, so I'll need to tend to them. After that, I should go to the well to fill up my water skin. I've been feeling a bit parched lately. And finally, I'd like to try out that new recipe I've been thinking about for dinner tonight. Perhaps I'll go gather some herbs from the garden for it.\"\n",
            "\n",
            "(If prompted to perform an action):\n",
            "\n",
            "action: goTo\n",
            "actionDetail: \"I'll go to the farm to check on my crops.\"\n",
            "\n",
            "action: eat\n",
            "actionDetail: \"I'll make a new recipe for dinner tonight using fresh herbs from the garden.\"\n",
            "\n",
            "action: drink\n",
            "actionDetail: \"I'll go to the well to fill up my water skin.\"\n",
            "\n",
            "action: speak\n",
            "actionDetail: \"I'll greet Ivan with a friendly hello and ask how his day is going.\"\n",
            "\n",
            "action: transfer\n",
            "actionDetail: \"I'll transfer some seeds to my inventory to plant new crops later.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert to ONNX format"
      ],
      "metadata": {
        "id": "GxE4H75e9xs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -qqq install optimum[exporters]\n",
        "!pip -qqq install onnxruntime\n",
        "!pip -qqq install optimum[onnxruntime]"
      ],
      "metadata": {
        "id": "Y1KtG1Xg96it",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b88934-93a0-4a72-da1f-fc0c6dfe8eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/417.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m \u001b[32m409.6/417.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m417.0/417.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!optimum-cli export onnx --model aomazic/Mistral-7B-Instruct-v0.2-veles aomazic/Mistral-7B-Instruct-v0.2-veles_onnx/"
      ],
      "metadata": {
        "id": "UZwxQnzHPECT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dac3503-725f-4f3a-d5b6-9f5348caa35d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-21 16:12:23.385079: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-21 16:12:23.385146: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-21 16:12:23.386764: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-21 16:12:24.526538: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Framework not specified. Using pt to export the model.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Downloading shards: 100% 3/3 [00:00<00:00,  3.87it/s]\n",
            "Loading checkpoint shards: 100% 3/3 [00:54<00:00, 18.27s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Automatic task detection to text-generation-with-past (possible synonyms are: causal-lm-with-past).\n",
            "Using the export variant default. Available variants are:\n",
            "    - default: The default ONNX variant.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "\n",
            "***** Exporting submodel 1/1: MistralForCausalLM *****\n",
            "Using framework PyTorch: 2.2.1+cu121\n",
            "Overriding 1 configuration item(s)\n",
            "\t- use_cache -> True\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_attn_mask_utils.py:114: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if (input_shape[-1] > 1 or self.sliding_window is not None) and self.is_causal:\n",
            "/usr/local/lib/python3.10/dist-packages/optimum/exporters/onnx/model_patcher.py:300: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if past_key_values_length > 0:\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py:120: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if seq_len > self.max_seq_len_cached:\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py:676: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if attention_mask.size() != (bsz, 1, q_len, kv_seq_len):\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "Saving external data to one file...\n",
            "Post-processing the exported models...\n",
            "Deduplicating shared (tied) weights...\n",
            "\n",
            "Validating ONNX model aomazic/Mistral-7B-Instruct-v0.2-veles_onnx/model.onnx...\n",
            "\t-[‚úì] ONNX model output names match reference model (present.13.key, present.12.key, present.20.value, present.23.value, present.31.value, logits, present.19.key, present.17.key, present.6.value, present.15.value, present.22.value, present.26.value, present.5.value, present.8.key, present.1.key, present.3.value, present.4.value, present.2.value, present.0.value, present.19.value, present.14.value, present.8.value, present.21.key, present.13.value, present.9.key, present.7.key, present.20.key, present.25.key, present.30.value, present.10.key, present.21.value, present.15.key, present.17.value, present.23.key, present.16.key, present.18.key, present.24.key, present.30.key, present.5.key, present.2.key, present.3.key, present.11.key, present.16.value, present.6.key, present.12.value, present.31.key, present.14.key, present.4.key, present.7.value, present.9.value, present.28.key, present.29.key, present.25.value, present.27.key, present.1.value, present.10.value, present.11.value, present.24.value, present.27.value, present.28.value, present.29.value, present.26.key, present.22.key, present.18.value, present.0.key)\n",
            "\t- Validating ONNX Model output \"logits\":\n",
            "\t\t-[‚úì] (2, 16, 32000) matches (2, 16, 32000)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.0.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.0.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.1.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.1.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.2.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.2.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.3.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.3.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.4.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.4.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.5.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.5.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.6.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.6.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.7.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.7.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.8.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.8.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.9.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.9.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.10.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.10.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.11.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.11.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.12.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.12.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.13.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.13.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.14.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.14.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.15.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.15.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.16.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.16.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.17.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.17.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.18.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.18.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.19.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.19.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.20.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.20.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.21.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.21.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.22.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.22.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.23.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.23.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.24.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.24.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.25.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.25.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.26.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.26.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.27.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.27.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.28.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.28.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.29.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.29.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.30.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.30.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.31.key\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.31.value\":\n",
            "\t\t-[‚úì] (2, 8, 32, 128) matches (2, 8, 32, 128)\n",
            "\t\t-[‚úì] all values close (atol: 1e-05)\n",
            "The ONNX export succeeded and the exported model was saved at: aomazic/Mistral-7B-Instruct-v0.2-veles_onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/aomazic/Mistral-7B-Instruct-v0.2-veles_onnx\n",
        "!git init\n",
        "!git remote add origin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQXn1XWYCxXd",
        "outputId": "97c62dd4-e8fa-4e4a-ec57-fc912bf494fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/.git/\n",
            "usage: git remote add [<options>] <name> <url>\n",
            "\n",
            "    -f, --fetch           fetch the remote branches\n",
            "    --tags                import all tags and associated objects when fetching\n",
            "                          or do not fetch any tag at all (--no-tags)\n",
            "    -t, --track <branch>  branch(es) to track\n",
            "    -m, --master <branch>\n",
            "                          master branch\n",
            "    --mirror[=(push|fetch)]\n",
            "                          set up remote as a mirror to push to or fetch from\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test ONNX model"
      ],
      "metadata": {
        "id": "cTrlWLkHHIJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from optimum.onnxruntime import ORTModelForQuestionAnswering\n",
        "import torch"
      ],
      "metadata": {
        "id": "-T3w9cYoLcUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Local path to the directory where the ONNX model and tokenizer are stored\n",
        "local_model_path = \"/content/aomazic/Mistral-7B-Instruct-v0.2-veles_onnx\"  # Update with your local model path\n",
        "\n",
        "# Load the tokenizer and model from the local directory\n",
        "tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
        "model = ORTModelForQuestionAnswering.from_pretrained(local_model_path, from_transformers=True)\n",
        "\n",
        "# Prepare the input\n",
        "input_text = (\n",
        "    \"<s>[INST] The following information represents a non-playable character in a game. \"\n",
        "    \"Use this information to simulate a response from the character. ###character: \"\n",
        "    \"{'name': 'Elena', 'age': 25, 'interests': ['Magic', 'Archery', 'Herbology'], 'description': \"\n",
        "    \"'Elena is a skilled mage who has a deep connection with nature.', 'morning_routine': \"\n",
        "    \"['Elena begins her day by meditating in the forest and collecting magical herbs.'], \"\n",
        "    \"'evening_routine': ['Elena practices her magic spells and experiments with potion-making under the moonlight.']} \"\n",
        "    \"###question: what to do today ###memory: \"\n",
        "    \"[{'date_created': '2023-02-02 08:00:00', 'recency': 0.8, 'importance': 0.7, 'relevance': 0.9, 'activity': \"\n",
        "    \"'Gathering rare ingredients for a powerful potion'}, {'date_created': '2023-02-01 10:00:00', 'recency': 0.7, \"\n",
        "    \"'importance': 0.6, 'relevance': 0.8, 'activity': 'Exploring ancient ruins to uncover lost magical artifacts'}, \"\n",
        "    \"{'date_created': '2023-01-31 12:00:00', 'recency': 0.6, 'importance': 0.5, 'relevance': 0.7, 'activity': \"\n",
        "    \"'Assisting villagers with magical ailments'}, {'date_created': '2023-01-30 14:00:00', 'recency': 0.5, 'importance': \"\n",
        "    \"0.4, 'relevance': 0.6, 'activity': 'Attending a council meeting to discuss magical defenses for the village'}, \"\n",
        "    \"{'date_created': '2023-01-29 16:00:00', 'recency': 0.4, 'importance': 0.3, 'relevance': 0.5, 'activity': \"\n",
        "    \"'Training apprentices in the ways of magic'}][/INST]\"\n",
        ")\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "# Prepare model inputs\n",
        "input_ids = inputs[\"input_ids\"]\n",
        "attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "# Print the outputs\n",
        "print(outputs)"
      ],
      "metadata": {
        "id": "Na7JDwuQ_ldP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "d8a69714-f3bc-4021-d6a3-9062758a047b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The argument `from_transformers` is deprecated, and will be removed in optimum 2.0.  Use `export` instead\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Cannot determine framework from given checkpoint location. There should be a pytorch_model*.bin for PyTorch or tf_model*.h5 for TensorFlow.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c7f3c52d114b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the tokenizer and model from the local directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mORTModelForQuestionAnswering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_transformers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Prepare the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optimum/onnxruntime/modeling_ort.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_id, export, force_download, use_auth_token, cache_dir, subfolder, config, local_files_only, provider, session_options, provider_options, use_io_binding, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mORTModel\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mORTModel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \"\"\"\n\u001b[0;32m--> 669\u001b[0;31m         return super().from_pretrained(\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0mexport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optimum/modeling_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_id, export, force_download, use_auth_token, cache_dir, subfolder, config, local_files_only, trust_remote_code, revision, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mfrom_pretrained_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_transformers\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexport\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_pretrained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         return from_pretrained_method(\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optimum/onnxruntime/modeling_ort.py\u001b[0m in \u001b[0;36m_from_transformers\u001b[0;34m(cls, model_id, config, use_auth_token, revision, force_download, cache_dir, subfolder, local_files_only, trust_remote_code, provider, session_options, provider_options, use_io_binding, task)\u001b[0m\n\u001b[1;32m    549\u001b[0m     ) -> \"ORTModel\":\n\u001b[1;32m    550\u001b[0m         \u001b[0;34m\"\"\"The method will be deprecated in future releases.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         return cls._export(\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optimum/onnxruntime/modeling_ort.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(cls, model_id, config, use_auth_token, revision, force_download, cache_dir, subfolder, local_files_only, trust_remote_code, provider, session_options, provider_options, use_io_binding, task)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0msave_dir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         main_export(\n\u001b[0m\u001b[1;32m    593\u001b[0m             \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_dir_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optimum/exporters/onnx/__main__.py\u001b[0m in \u001b[0;36mmain_export\u001b[0;34m(model_name_or_path, output, task, opset, device, dtype, fp16, optimize, monolith, no_post_process, framework, atol, cache_dir, trust_remote_code, pad_token_id, subfolder, revision, force_download, local_files_only, use_auth_token, for_ort, do_validation, model_kwargs, custom_onnx_configs, fn_get_submodels, use_subprocess, _variant, library_name, legacy, no_dynamic_axes, do_constant_folding, **kwargs_shapes)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTasksManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_from_synonym\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mframework\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTasksManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetermine_framework\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     library_name = TasksManager.infer_library_from_model(\n\u001b[1;32m    216\u001b[0m         \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibrary_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibrary_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optimum/exporters/tasks.py\u001b[0m in \u001b[0;36mdetermine_framework\u001b[0;34m(model_name_or_path, subfolder, framework, cache_dir)\u001b[0m\n\u001b[1;32m   1491\u001b[0m                 )\n\u001b[1;32m   1492\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1493\u001b[0;31m                 raise FileNotFoundError(\n\u001b[0m\u001b[1;32m   1494\u001b[0m                     \u001b[0;34m\"Cannot determine framework from given checkpoint location.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m                     \u001b[0;34mf\" There should be a {Path(WEIGHTS_NAME).stem}*{Path(WEIGHTS_NAME).suffix} for PyTorch\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot determine framework from given checkpoint location. There should be a pytorch_model*.bin for PyTorch or tf_model*.h5 for TensorFlow."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "# Local path to the ONNX model\n",
        "local_model_path = \"/content/aomazic/Mistral-7B-Instruct-v0.2-veles_onnx/model.onnx\"\n",
        "\n",
        "# Initialize an ONNX Runtime session\n",
        "session = ort.InferenceSession(local_model_path)\n",
        "\n",
        "# Print input names and shapes\n",
        "for idx, input_meta in enumerate(session.get_inputs()):\n",
        "    print(f\"Input {idx}: name={input_meta.name}, shape={input_meta.shape}, type={input_meta.type}\")\n",
        "\n",
        "# Print output names and shapes\n",
        "for idx, output_meta in enumerate(session.get_outputs()):\n",
        "    print(f\"Output {idx}: name={output_meta.name}, shape={output_meta.shape}, type={output_meta.type}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZaJua0BLJ0Jh",
        "outputId": "af0c1614-fc69-4c3f-f089-e8e0c60de15a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input 0: name=input_ids, shape=['batch_size', 'sequence_length'], type=tensor(int64)\n",
            "Input 1: name=attention_mask, shape=['batch_size', 'past_sequence_length + 1'], type=tensor(int64)\n",
            "Input 2: name=position_ids, shape=['batch_size', 'sequence_length'], type=tensor(int64)\n",
            "Input 3: name=past_key_values.0.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 4: name=past_key_values.0.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 5: name=past_key_values.1.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 6: name=past_key_values.1.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 7: name=past_key_values.2.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 8: name=past_key_values.2.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 9: name=past_key_values.3.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 10: name=past_key_values.3.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 11: name=past_key_values.4.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 12: name=past_key_values.4.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 13: name=past_key_values.5.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 14: name=past_key_values.5.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 15: name=past_key_values.6.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 16: name=past_key_values.6.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 17: name=past_key_values.7.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 18: name=past_key_values.7.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 19: name=past_key_values.8.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 20: name=past_key_values.8.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 21: name=past_key_values.9.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 22: name=past_key_values.9.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 23: name=past_key_values.10.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 24: name=past_key_values.10.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 25: name=past_key_values.11.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 26: name=past_key_values.11.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 27: name=past_key_values.12.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 28: name=past_key_values.12.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 29: name=past_key_values.13.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 30: name=past_key_values.13.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 31: name=past_key_values.14.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 32: name=past_key_values.14.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 33: name=past_key_values.15.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 34: name=past_key_values.15.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 35: name=past_key_values.16.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 36: name=past_key_values.16.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 37: name=past_key_values.17.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 38: name=past_key_values.17.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 39: name=past_key_values.18.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 40: name=past_key_values.18.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 41: name=past_key_values.19.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 42: name=past_key_values.19.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 43: name=past_key_values.20.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 44: name=past_key_values.20.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 45: name=past_key_values.21.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 46: name=past_key_values.21.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 47: name=past_key_values.22.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 48: name=past_key_values.22.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 49: name=past_key_values.23.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 50: name=past_key_values.23.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 51: name=past_key_values.24.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 52: name=past_key_values.24.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 53: name=past_key_values.25.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 54: name=past_key_values.25.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 55: name=past_key_values.26.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 56: name=past_key_values.26.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 57: name=past_key_values.27.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 58: name=past_key_values.27.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 59: name=past_key_values.28.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 60: name=past_key_values.28.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 61: name=past_key_values.29.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 62: name=past_key_values.29.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 63: name=past_key_values.30.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 64: name=past_key_values.30.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 65: name=past_key_values.31.key, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Input 66: name=past_key_values.31.value, shape=['batch_size', 8, 'past_sequence_length', 128], type=tensor(float)\n",
            "Output 0: name=logits, shape=['batch_size', 'sequence_length', 32000], type=tensor(float)\n",
            "Output 1: name=present.0.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 2: name=present.0.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 3: name=present.1.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 4: name=present.1.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 5: name=present.2.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 6: name=present.2.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 7: name=present.3.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 8: name=present.3.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 9: name=present.4.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 10: name=present.4.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 11: name=present.5.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 12: name=present.5.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 13: name=present.6.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 14: name=present.6.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 15: name=present.7.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 16: name=present.7.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 17: name=present.8.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 18: name=present.8.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 19: name=present.9.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 20: name=present.9.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 21: name=present.10.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 22: name=present.10.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 23: name=present.11.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 24: name=present.11.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 25: name=present.12.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 26: name=present.12.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 27: name=present.13.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 28: name=present.13.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 29: name=present.14.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 30: name=present.14.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 31: name=present.15.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 32: name=present.15.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 33: name=present.16.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 34: name=present.16.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 35: name=present.17.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 36: name=present.17.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 37: name=present.18.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 38: name=present.18.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 39: name=present.19.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 40: name=present.19.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 41: name=present.20.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 42: name=present.20.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 43: name=present.21.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 44: name=present.21.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 45: name=present.22.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 46: name=present.22.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 47: name=present.23.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 48: name=present.23.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 49: name=present.24.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 50: name=present.24.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 51: name=present.25.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 52: name=present.25.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 53: name=present.26.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 54: name=present.26.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 55: name=present.27.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 56: name=present.27.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 57: name=present.28.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 58: name=present.28.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 59: name=present.29.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 60: name=present.29.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 61: name=present.30.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 62: name=present.30.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 63: name=present.31.key, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n",
            "Output 64: name=present.31.value, shape=['batch_size', 8, 'past_sequence_length + 1', 128], type=tensor(float)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOa4NVZ+4UMN4VKPCcNfsuh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01a794b0aecf49d1b855e8130b31fe85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35edc87da9444d25951f45230057d75d",
              "IPY_MODEL_7ed567aa51874eee80f33bba2f4341f9",
              "IPY_MODEL_4e67cb9cfd5442e28451524444c5775d"
            ],
            "layout": "IPY_MODEL_830e8e36ac6c4b3cac69dd36046704af"
          }
        },
        "35edc87da9444d25951f45230057d75d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2dcfe011ce2448289ec0fad1ef05ddf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_049b5d49b08b4a8cb13fafc0945709b4",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá"
          }
        },
        "7ed567aa51874eee80f33bba2f4341f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7de566a21fda4f93ba9786714b2b6fd5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f5794fb85fc401597423eba62b4130b",
            "value": 1
          }
        },
        "4e67cb9cfd5442e28451524444c5775d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7e3fdbc9513413e9af2b254834e5b14",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_281dd5b0ce8e424bac9ceb1ddd955fc8",
            "value": "‚Äá20/0‚Äá[00:00&lt;00:00,‚Äá981.30‚Äáexamples/s]"
          }
        },
        "830e8e36ac6c4b3cac69dd36046704af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2dcfe011ce2448289ec0fad1ef05ddf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "049b5d49b08b4a8cb13fafc0945709b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7de566a21fda4f93ba9786714b2b6fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9f5794fb85fc401597423eba62b4130b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7e3fdbc9513413e9af2b254834e5b14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "281dd5b0ce8e424bac9ceb1ddd955fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9012b656a5194a859b610c236e8c394c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_191b7047f92d43a99f392708ef69f779",
              "IPY_MODEL_ee9975e80bb347d29a5b3f50545b3a75",
              "IPY_MODEL_cf402e40c4134cc0b10258c8ebbca45c"
            ],
            "layout": "IPY_MODEL_3f852f43aa734f6fafe8f881228d2a87"
          }
        },
        "191b7047f92d43a99f392708ef69f779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb68519f18a4438388e633f500ab86d0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2b9a272fbbb44c08a4e61f311ebe3659",
            "value": "Map:‚Äá100%"
          }
        },
        "ee9975e80bb347d29a5b3f50545b3a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16fad0b60a6847c68dbc63215865ce29",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_662a7e35ac664d73ad437a48409feea7",
            "value": 20
          }
        },
        "cf402e40c4134cc0b10258c8ebbca45c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caa431ac83194f22a63e170a982c7814",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ae37c86d0f9142faa3b1c825475029b0",
            "value": "‚Äá20/20‚Äá[00:00&lt;00:00,‚Äá1072.78‚Äáexamples/s]"
          }
        },
        "3f852f43aa734f6fafe8f881228d2a87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb68519f18a4438388e633f500ab86d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b9a272fbbb44c08a4e61f311ebe3659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16fad0b60a6847c68dbc63215865ce29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "662a7e35ac664d73ad437a48409feea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "caa431ac83194f22a63e170a982c7814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae37c86d0f9142faa3b1c825475029b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1374fdce622043a5acbb20fef97178b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67df3a3703c14c9ca4b9e41a4b9a0313",
              "IPY_MODEL_50e176b9632448e79c1da388a9ae073a",
              "IPY_MODEL_be39d8c4dcc04b2db46dcda7c24f342d"
            ],
            "layout": "IPY_MODEL_e5332fa247fc4eafb8d5da6638e74c65"
          }
        },
        "67df3a3703c14c9ca4b9e41a4b9a0313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f87b2f86cfa446a8849e85c4a52310d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_17678cd3ffe84a18b2fcdface41452ff",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "50e176b9632448e79c1da388a9ae073a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aaa45b5f6484296bd4b3930902a17d8",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee0d0650c73143e488cd248c9cff5e97",
            "value": 3
          }
        },
        "be39d8c4dcc04b2db46dcda7c24f342d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d24dc10e9640464b86f21166cc0283e9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_22002d020a0f47f7aa7877b1bbcfe256",
            "value": "‚Äá3/3‚Äá[00:08&lt;00:00,‚Äá‚Äá2.87s/it]"
          }
        },
        "e5332fa247fc4eafb8d5da6638e74c65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f87b2f86cfa446a8849e85c4a52310d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17678cd3ffe84a18b2fcdface41452ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9aaa45b5f6484296bd4b3930902a17d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee0d0650c73143e488cd248c9cff5e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d24dc10e9640464b86f21166cc0283e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22002d020a0f47f7aa7877b1bbcfe256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dbd7e691f5741da87d2cb4828049976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f66442be8c6f4e84a73b972c1fcf67b7",
              "IPY_MODEL_55ccf9fdf0724378a1c75716c40af252",
              "IPY_MODEL_7964818d2fb64f5bb71f98a2927a1525"
            ],
            "layout": "IPY_MODEL_805041d8d6734dd4812aa6054d824bb6"
          }
        },
        "f66442be8c6f4e84a73b972c1fcf67b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_863015bfcc2842598f1234cb03188d83",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ddd130b963484cc8b7b058e3ab5e0324",
            "value": "Map:‚Äá100%"
          }
        },
        "55ccf9fdf0724378a1c75716c40af252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf14ebb71af8472c83fdd3136c9a6106",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_601d1e65c62342d4a6ee68a6756f1adb",
            "value": 20
          }
        },
        "7964818d2fb64f5bb71f98a2927a1525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aed90636dfca4c13b8aba1c6b01b8c37",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b65d22d7ef0c42cb84a22fc6d86a592d",
            "value": "‚Äá20/20‚Äá[00:00&lt;00:00,‚Äá752.21‚Äáexamples/s]"
          }
        },
        "805041d8d6734dd4812aa6054d824bb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "863015bfcc2842598f1234cb03188d83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddd130b963484cc8b7b058e3ab5e0324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf14ebb71af8472c83fdd3136c9a6106": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "601d1e65c62342d4a6ee68a6756f1adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aed90636dfca4c13b8aba1c6b01b8c37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b65d22d7ef0c42cb84a22fc6d86a592d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dadc99c937c64bfeaa464d253540fd86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9d98b3e29a44ba6bbf0bc6ed56ce8d5",
              "IPY_MODEL_9dbb71f7ecc042769bc68ea93003d683",
              "IPY_MODEL_defcd6dd974d41de93e82856642b854c",
              "IPY_MODEL_d110a398bec84383833271fd6f360e5c"
            ],
            "layout": "IPY_MODEL_cf4518d6206b4b7b9ece267b5c01b4d1"
          }
        },
        "8c6c7dfe3ffb49e48440a70e677c0057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d91e2a8b63aa4da69f2aedff7d21ed32",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6869cc34401642d0909ad7e5cf1694cc",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "c8f74cb4140141daaf18a33d5fc89c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_09cbc84fa5ca4760b3d2e28bfb8627a0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ba30680c02cd4f9db21883fca3545362",
            "value": ""
          }
        },
        "04e4c7ba92d2466b9297bc9a7308bd77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_3bce2df409874c31bc348c4fa82199d2",
            "style": "IPY_MODEL_2d2929f4929247e196e142290fb99d39",
            "value": true
          }
        },
        "797ef7da27d643a9a3c10ddf057c25e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d2bde1c1b44743b6888a1893979f88a8",
            "style": "IPY_MODEL_b6e48f5113d54de296dafd9a46243a2d",
            "tooltip": ""
          }
        },
        "12ff394f655645a2bd5acb3a86981275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d66386d038394b50bd70610db730982e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8efb8df1649d46e98c5636dc4335fea4",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "cf4518d6206b4b7b9ece267b5c01b4d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "d91e2a8b63aa4da69f2aedff7d21ed32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6869cc34401642d0909ad7e5cf1694cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09cbc84fa5ca4760b3d2e28bfb8627a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba30680c02cd4f9db21883fca3545362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bce2df409874c31bc348c4fa82199d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d2929f4929247e196e142290fb99d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2bde1c1b44743b6888a1893979f88a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6e48f5113d54de296dafd9a46243a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d66386d038394b50bd70610db730982e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8efb8df1649d46e98c5636dc4335fea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cac2ce1711d418ead60fade9826002c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_071c2d0f9da9499cb715d9dd6b94d6bc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_05dc1265eed64c58bcd6c5abf3d84ef4",
            "value": "Connecting..."
          }
        },
        "071c2d0f9da9499cb715d9dd6b94d6bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05dc1265eed64c58bcd6c5abf3d84ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9d98b3e29a44ba6bbf0bc6ed56ce8d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd940318283c4bc096bb7cf84c64b5bd",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a4421ff6121041268e85925860c17b59",
            "value": "Token is valid (permission: write)."
          }
        },
        "9dbb71f7ecc042769bc68ea93003d683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c68a5ed76790439e9332d442d2d66770",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2ab31a4d78b44ed384521a51736b469e",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "defcd6dd974d41de93e82856642b854c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a0696e6354a41f4af6afa6cff7d8dd3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_80d2bb2cc2ef4637bbff2288e7287964",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "d110a398bec84383833271fd6f360e5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f531f3222e5848a68dd24b486af68066",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_610569f3b0f3489bb3c726fe159ee406",
            "value": "Login successful"
          }
        },
        "fd940318283c4bc096bb7cf84c64b5bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4421ff6121041268e85925860c17b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c68a5ed76790439e9332d442d2d66770": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ab31a4d78b44ed384521a51736b469e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a0696e6354a41f4af6afa6cff7d8dd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80d2bb2cc2ef4637bbff2288e7287964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f531f3222e5848a68dd24b486af68066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "610569f3b0f3489bb3c726fe159ee406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}